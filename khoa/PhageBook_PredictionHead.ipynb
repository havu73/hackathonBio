{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6ZgtvN84bJM",
        "outputId": "7a12f5e7-18dd-48ef-9769-55794fff483c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNNResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "    super(CNNResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "        nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride*2, bias=False),\n",
        "        nn.BatchNorm1d(out_channels)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = self.shortcut(x)\n",
        "    # print(f\"Residual shape: {residual.shape}\")\n",
        "    out = self.conv1(x)\n",
        "    # print(f\"Conv1 shape: {out.shape}\")\n",
        "    out = self.bn1(out)\n",
        "    # print(f\"BN1 shape: {out.shape}\")\n",
        "    out = F.relu(out)\n",
        "    # print(f\"ReLU shape: {out.shape}\")\n",
        "    out = self.conv2(out)\n",
        "    # print(f\"Conv2 shape: {out.shape}\")\n",
        "    out = self.bn2(out)\n",
        "    # print(f\"BN2 shape: {out.shape}\")\n",
        "    out += residual\n",
        "    # print(f\"Residual added shape: {out.shape}\")\n",
        "    out = F.relu(out)\n",
        "    # print(f\"Final ReLU shape: {out.shape}\")\n",
        "    return out\n",
        "\n",
        "class BacteriaNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, output_dim, kernel_size, padding, avg_poolsize, embedding_reduction_factor, resblock_num, stride, dropout_rate = 0.2):\n",
        "        super(BacteriaNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embedding_dim, embedding_dim//2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm1d(embedding_dim//2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        for i in range(resblock_num):\n",
        "            setattr(self, f'resblock{i+1}', CNNResidualBlock(embedding_dim//2, embedding_dim//2, kernel_size=kernel_size, padding=padding, stride=stride))\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(avg_poolsize)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(avg_poolsize*embedding_dim//2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # print(f\"Input shape: {x.shape}\")\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        # print(f\"After maxpool: {x.shape}\")\n",
        "        for i in range(resblock_num):\n",
        "            x = getattr(self, f'resblock{i+1}')(x)\n",
        "            # print(f\"After resblock{i+1}: {x.shape}\")\n",
        "        # print(f\"After resblock4: {x.shape}\")\n",
        "        x = self.avgpool(x)\n",
        "        # print(f\"After avgpool: {x.shape}\")\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # print(f\"After view: {x.shape}\")\n",
        "        x = self.dropout(x)\n",
        "        # print(f\"After dropout: {x.shape}\")\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HgRL_sAIyqT2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViralNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, length, output_dim, hidden_dims=[128, 64], dropout_rate = 0.2):\n",
        "        super(ViralNN, self).__init__()\n",
        "\n",
        "        fc_input_dim = embedding_dim * length\n",
        "        layers = []\n",
        "        current_dim = fc_input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(current_dim, output_dim))\n",
        "        self.fc_layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ans6EEIVEZad"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_size = 1234\n",
        "MAX_BACTERIA_LENGTH = 50000000\n",
        "bacteria_max_seq_len = int(MAX_BACTERIA_LENGTH/131000)\n",
        "viral_max_seq_len = 2\n",
        "embedding_dim = 64 # use small to test, need to change to 4096\n",
        "embedding_reduction_factor = 2\n",
        "kernel_size = 11 # set to odd number smaller than embedding size\n",
        "padding = (kernel_size - 1) // 2\n",
        "stride = 2\n",
        "avg_poolsize = 2\n",
        "resblock_num = 2\n",
        "output_dim = 256\n",
        "dropout_rate = 0.2\n",
        "hidden_dims = [embedding_dim//2, embedding_dim//4]\n",
        "\n",
        "class PhINN(nn.Module):\n",
        "    def __init__(self, bacteria_nn, viral_nn, output_dim):\n",
        "        super(PhINN, self).__init__()\n",
        "        self.bacteria_nn = bacteria_nn\n",
        "        self.viral_nn = viral_nn\n",
        "        self.fc = nn.Linear(output_dim*2, output_dim)\n",
        "        self.fc2 = nn.Linear(output_dim, 1)\n",
        "\n",
        "    def forward(self, bacteria_input, viral_input):\n",
        "        bacteria_output = self.bacteria_nn(bacteria_input)\n",
        "        viral_output = self.viral_nn(viral_input)\n",
        "\n",
        "        combined_output = torch.cat((bacteria_output, viral_output), dim=1)\n",
        "        output = self.fc(combined_output)\n",
        "        logits = self.fc2(output)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "\n",
        "bacteria_nn = BacteriaNN(embedding_dim = embedding_dim, kernel_size = kernel_size, padding = padding, stride = stride, avg_poolsize = avg_poolsize, resblock_num = resblock_num, embedding_reduction_factor = embedding_reduction_factor, output_dim = output_dim)\n",
        "viral_nn = ViralNN(embedding_dim = embedding_dim, length=viral_max_seq_len, output_dim=output_dim, hidden_dims=hidden_dims, dropout_rate = dropout_rate)\n",
        "\n",
        "# Create an instance of PhINN\n",
        "phinn_model = PhINN(bacteria_nn, viral_nn, output_dim=output_dim).to(device)\n",
        "\n",
        "# Example input tensors\n",
        "bacteria_input = torch.randn(data_size, bacteria_max_seq_len, embedding_dim)\n",
        "viral_input = torch.randn(data_size, viral_max_seq_len, embedding_dim)\n",
        "example_labels = torch.randint(0, 2, (data_size,))"
      ],
      "metadata": {
        "id": "_WbK2S3mHjCJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(phinn_model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "data_size = len(bacteria_input)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    phinn_model.train()\n",
        "    train_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    num_batches = (data_size + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in tqdm(range(0, data_size, batch_size)):\n",
        "        # Get the batch\n",
        "        bacteria_input_load = bacteria_input[i:i+batch_size]\n",
        "        viral_input_load = viral_input[i:i+batch_size]\n",
        "        labels_load = example_labels[i:i+batch_size]\n",
        "\n",
        "        bacteria_input_load = bacteria_input_load.to(device)\n",
        "        viral_input_load = viral_input_load.to(device)\n",
        "        labels_load = labels_load.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = phinn_model(bacteria_input_load, viral_input_load)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs.squeeze(), labels_load.float())\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predicted_labels = (outputs.squeeze() > 0.5).float()  # Threshold at 0.5\n",
        "        correct_predictions += (predicted_labels == labels_load).sum().item()\n",
        "        total_samples += labels_load.size(0)\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    avg_loss = train_loss / num_batches\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    # Print the average loss and accuracy for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kigPLKbKQS6F",
        "outputId": "3555aa5d-cb67-44e3-c8b5-16de1bf3310e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 63.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7175, Accuracy: 0.4903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 61.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 0.5432, Accuracy: 0.7334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 67.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 0.2806, Accuracy: 0.8849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 64.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 0.2410, Accuracy: 0.9100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 59.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 0.1048, Accuracy: 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 66.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 0.0205, Accuracy: 0.9943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 67.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 0.0146, Accuracy: 0.9943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 68.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 0.0767, Accuracy: 0.9708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 68.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.0813, Accuracy: 0.9668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:01<00:00, 69.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 0.0321, Accuracy: 0.9919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}